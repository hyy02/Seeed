import logging
import time
import numpy as np
import torch
from dataclasses import asdict, dataclass
from pathlib import Path
from pprint import pformat
from collections import deque
from enum import Enum, auto

from lerobot.cameras import (  # noqa: F401
    CameraConfig,  # noqa: F401
)
from lerobot.cameras.opencv.configuration_opencv import OpenCVCameraConfig  # noqa: F401
from lerobot.cameras.realsense.configuration_realsense import RealSenseCameraConfig  # noqa: F401
from lerobot.configs import parser
from lerobot.configs.policies import PreTrainedConfig
from lerobot.datasets.image_writer import safe_stop_image_writer
from lerobot.datasets.lerobot_dataset import LeRobotDataset
from lerobot.datasets.utils import build_dataset_frame, hw_to_dataset_features
from lerobot.datasets.video_utils import VideoEncodingManager
from lerobot.policies.factory import make_policy
from lerobot.policies.pretrained import PreTrainedPolicy
from lerobot.robots import (  # noqa: F401
    Robot,
    RobotConfig,
    bi_so100_follower,
    hope_jr,
    koch_follower,
    make_robot_from_config,
    so100_follower,
    so101_follower,
    xlerobot,
)
from lerobot.teleoperators import (  # noqa: F401
    Teleoperator,
    TeleoperatorConfig,
    bi_so100_leader,
    homunculus,
    koch_leader,
    make_teleoperator_from_config,
    so100_leader,
    so101_leader,
    xlerobot_vr,
)
from lerobot.teleoperators.keyboard.teleop_keyboard import KeyboardTeleop
from lerobot.teleoperators.xlerobot_vr.xlerobot_vr import XLerobotVRTeleop, init_vr_listener
from lerobot.utils.control_utils import (
    init_keyboard_listener,
    is_headless,
    predict_action,
    sanity_check_dataset_name,
    sanity_check_dataset_robot_compatibility,
)
from lerobot.utils.robot_utils import busy_wait
from lerobot.utils.utils import (
    get_safe_torch_device,
    init_logging,
    log_say,
)
from lerobot.utils.visualization_utils import init_rerun, log_rerun_data

# å®šä¹‰çŠ¶æ€æšä¸¾
class RobotState(Enum):
    NAVIGATION = auto()    # å¯¼èˆªçŠ¶æ€
    OPERATION = auto()     # æ“ä½œçŠ¶æ€
    END = auto()           # ç»“æŸçŠ¶æ€

GLOBAL_BACK_GOAL = np.array([-99.1578, -67.1670, 21.1723, 99.1829, 5.7592, 0.8043, 99.8230, -67.0739, 21.0242, 99.1322, -0.6326, 0.4778])
GLOBAL_OPEN_GOAL = np.array([-99.1578, -67.1670, 21.1723, 99.1829, 5.7592, 36, 99.8230, -67.0739, 21.0242, 99.1322, -0.6326, 36])
def reset_follower_position(robot, target_position, steps=50, delay=0.015, start_position=None):
    """
    è®©æœºå™¨äººå¹³æ»‘ç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®ï¼Œç”Ÿæˆå¯è®°å½•çš„åŠ¨ä½œåºåˆ—
    
    Args:
        robot: æœºå™¨äººå¯¹è±¡ (éœ€è¦æœ‰ bus1, bus2 å±æ€§)
        target_position: ç›®æ ‡ä½ç½®æ•°ç»„ [left_arm_joints..., right_arm_joints...]
        steps: è½¨è¿¹æ­¥æ•° (é»˜è®¤150)
        delay: æ¯æ­¥å»¶è¿Ÿæ—¶é—´ (é»˜è®¤15ms)
    
    Returns:
        list: åŠ¨ä½œåºåˆ—ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªåŠ¨ä½œå­—å…¸
    """
    # è¯»å–å½“å‰ä½ç½®
    left_current_position_dict = robot.bus1.sync_read("Present_Position")
    # å°†é”®åç»Ÿä¸€ä¸º '<motor_name>.pos' å½¢å¼ï¼Œä¾¿äºä¸å…¶ä»–ä»£ç ä¸­çš„é”®åä¸€è‡´
    right_current_position_dict = robot.bus2.sync_read("Present_Position")
    if start_position is not None:
        left_current_position, right_current_position = start_position[0:6], start_position[6:12]
    else:
        left_current_position = np.array(
            [left_current_position_dict[name] for name in left_current_position_dict], dtype=np.float32
        )
        right_current_position = np.array(
            [right_current_position_dict[name] for name in right_current_position_dict], dtype=np.float32
        )
    
    # åˆ†ç¦»å·¦å³è‡‚ç›®æ ‡ä½ç½®
    left_target_position, right_target_position = target_position[0:6], target_position[6:12]
    
    # ç”Ÿæˆå¹³æ»‘è½¨è¿¹ (ä¿æŒæœ€åå‡ ä¸ªå…³èŠ‚ä¸å˜)
    if start_position is None:
        left_trajectory = torch.from_numpy(
            np.linspace(left_current_position, np.concatenate((left_target_position, left_current_position[-2:])), steps)
        )
        right_trajectory = torch.from_numpy(
            np.linspace(right_current_position[:-3], right_target_position, steps)
        )
    else:
        left_trajectory = torch.from_numpy(
            np.linspace(left_current_position, left_target_position, steps)
        )
        right_trajectory = torch.from_numpy(
            np.linspace(right_current_position, right_target_position, steps)
        )
    
    # ç”ŸæˆåŠ¨ä½œåºåˆ—
    action_sequence = []
    left_current_position_dict = [
        'left_arm_shoulder_pan.pos',
        'left_arm_shoulder_lift.pos',
        'left_arm_elbow_flex.pos',
        'left_arm_wrist_flex.pos',
        'left_arm_wrist_roll.pos',
        'left_arm_gripper.pos',
    ]
    right_current_position_dict = [
        'right_arm_shoulder_pan.pos',
        'right_arm_shoulder_lift.pos',
        'right_arm_elbow_flex.pos',
        'right_arm_wrist_flex.pos',
        'right_arm_wrist_roll.pos',
        'right_arm_gripper.pos'
    ]
    if start_position is None:
        left_current_position_dict += ['head_motor_1.pos', 'head_motor_2.pos']
    for left_pose, right_pose in zip(left_trajectory, right_trajectory):
        left_action_dict = dict(zip(left_current_position_dict, left_pose, strict=False))
        right_action_dict = dict(zip(right_current_position_dict, right_pose, strict=False))
        if start_position is None:
            head_motor_dict = {}
        else:
            head_motor_dict = {
                'head_motor_1.pos': 8.982,
                'head_motor_2.pos': 28.8703,
            }
        base_action_dict = {
            "x.vel": 0,
            "y.vel": 0,
            "theta.vel": 0,
        }
        
        # åˆå¹¶ä¸ºå®Œæ•´çš„åŠ¨ä½œå­—å…¸
        action_dict = {**left_action_dict, **head_motor_dict, **right_action_dict, **base_action_dict}
        action_sequence.append(action_dict)
    
    return action_sequence

def queue_reset_actions(action_queue, robot, target_position, steps=50, start_position=None):
    """
    å°†é‡ç½®åŠ¨ä½œåºåˆ—åŠ å…¥é˜Ÿåˆ—
    
    Args:
        action_queue: åŠ¨ä½œé˜Ÿåˆ—
        robot: æœºå™¨äººå¯¹è±¡
        target_position: ç›®æ ‡ä½ç½®
        steps: è½¨è¿¹æ­¥æ•°
    """
    action_sequence = reset_follower_position(robot, target_position, steps, start_position=start_position)
    action_queue.extend(action_sequence)
    logging.info(f"Queued {len(action_sequence)} reset actions")


class StateMachine:
    """çŠ¶æ€æœºç®¡ç†æœºå™¨äººçš„ä¸‰ä¸ªçŠ¶æ€ï¼šå¯¼èˆªã€æ“ä½œã€ç»“æŸ"""
    
    def __init__(self, initial_state=RobotState.NAVIGATION, state_check_interval=300):
        self.current_state = initial_state
        self.state_check_interval = state_check_interval
        self.step_count = 0
        self.state_transition_log = []
        self.operation_count = 0  # è®°å½•è¿›å…¥æ“ä½œçŠ¶æ€çš„æ¬¡æ•°
        self.max_operation_cycles = 3  # æœ€å¤§æ“ä½œå¾ªç¯æ¬¡æ•°
        
    def update(self, observation, action_queue, robot, teleop):
        """æ›´æ–°çŠ¶æ€æœºï¼Œæ¯state_check_intervalæ­¥æ£€æŸ¥çŠ¶æ€è½¬æ¢"""
        self.step_count += 1
        
        # æ¯state_check_intervalæ­¥æ£€æŸ¥çŠ¶æ€è½¬æ¢
        if self.step_count % self.state_check_interval == 0:
            new_state = self._evaluate_state_transition(observation, action_queue, robot, teleop)
            if new_state != self.current_state:
                self._transition_to_state(new_state, robot, teleop)
                
        return self.current_state
    
    def _evaluate_state_transition(self, observation, action_queue, robot, teleop):
        """è¯„ä¼°çŠ¶æ€è½¬æ¢æ¡ä»¶"""
        
        if self.current_state == RobotState.NAVIGATION:
            # å¯¼èˆªçŠ¶æ€è½¬æ¢æ¡ä»¶ï¼šå¦‚æœåŠ¨ä½œé˜Ÿåˆ—ä¸ºç©ºä¸”æœºå™¨äººå¤„äºç¨³å®šä½ç½®ï¼Œè½¬åˆ°æ“ä½œçŠ¶æ€
            if len(action_queue) == 0 and self._is_robot_stable(observation):
                return RobotState.OPERATION
                
        elif self.current_state == RobotState.OPERATION:
            # æ“ä½œçŠ¶æ€è½¬æ¢æ¡ä»¶ï¼šå¦‚æœæ“ä½œå®Œæˆï¼Œè½¬å›å¯¼èˆªçŠ¶æ€æˆ–ç»“æŸçŠ¶æ€
            if self._is_operation_complete(observation):
                self.operation_count += 1
                logging.info(f"æ“ä½œå®Œæˆï¼Œç¬¬ {self.operation_count} æ¬¡æ“ä½œå¾ªç¯")
                
                # å¦‚æœè¾¾åˆ°æœ€å¤§æ“ä½œå¾ªç¯æ¬¡æ•°ï¼Œè½¬åˆ°ç»“æŸçŠ¶æ€
                if self.operation_count >= self.max_operation_cycles:
                    return RobotState.END
                else:
                    # å¦åˆ™è½¬å›å¯¼èˆªçŠ¶æ€è¿›è¡Œä¸‹ä¸€æ¬¡æ“ä½œ
                    return RobotState.NAVIGATION
                    
        elif self.current_state == RobotState.END:
            # ç»“æŸçŠ¶æ€ä¸è¿›è¡Œè½¬æ¢
            return RobotState.END
                
        return self.current_state  # ä¿æŒå½“å‰çŠ¶æ€
    
    def _transition_to_state(self, new_state, robot, teleop):
        """æ‰§è¡ŒçŠ¶æ€è½¬æ¢"""
        old_state = self.current_state
        self.current_state = new_state
        
        # è®°å½•çŠ¶æ€è½¬æ¢
        transition_msg = f"çŠ¶æ€è½¬æ¢: {old_state.name} -> {new_state.name}"
        self.state_transition_log.append(transition_msg)
        logging.info(transition_msg)
        log_say(transition_msg)
        
        # æ‰§è¡ŒçŠ¶æ€ç‰¹å®šçš„åˆå§‹åŒ–æ“ä½œ
        if new_state == RobotState.NAVIGATION:
            self._enter_navigation_state(robot, teleop)
        elif new_state == RobotState.OPERATION:
            self._enter_operation_state(robot, teleop)
        elif new_state == RobotState.END:
            self._enter_end_state(robot, teleop)
    
    def _enter_navigation_state(self, robot, teleop):
        """è¿›å…¥å¯¼èˆªçŠ¶æ€çš„åˆå§‹åŒ–æ“ä½œ"""
        logging.info("è¿›å…¥å¯¼èˆªçŠ¶æ€ï¼šæœºå™¨äººå°†ç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®")
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å¯¼èˆªç›¸å…³çš„åˆå§‹åŒ–ä»£ç 
        
    def _enter_operation_state(self, robot, teleop):
        """è¿›å…¥æ“ä½œçŠ¶æ€çš„åˆå§‹åŒ–æ“ä½œ"""
        logging.info(f"è¿›å…¥æ“ä½œçŠ¶æ€ï¼šæ‰§è¡Œç¬¬ {self.operation_count + 1} æ¬¡å…·ä½“ä»»åŠ¡æ“ä½œ")
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ“ä½œç›¸å…³çš„åˆå§‹åŒ–ä»£ç 
    
    def _enter_end_state(self, robot, teleop):
        """è¿›å…¥ç»“æŸçŠ¶æ€çš„åˆå§‹åŒ–æ“ä½œ"""
        logging.info("è¿›å…¥ç»“æŸçŠ¶æ€ï¼šå®Œæˆæ‰€æœ‰æ“ä½œä»»åŠ¡")
        log_say("ä»»åŠ¡å®Œæˆï¼Œæ‰€æœ‰æ“ä½œå¾ªç¯å·²ç»“æŸ")
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ ç»“æŸç›¸å…³çš„æ¸…ç†ä»£ç 
    
    def _is_robot_stable(self, observation):
        """æ£€æŸ¥æœºå™¨äººæ˜¯å¦å¤„äºç¨³å®šçŠ¶æ€"""
        # ç¤ºä¾‹ï¼šæ£€æŸ¥å…³èŠ‚é€Ÿåº¦æ˜¯å¦æ¥è¿‘é›¶
        try:
            velocity_threshold = 0.1
            velocities = []
            
            # ä»è§‚æµ‹æ•°æ®ä¸­æå–é€Ÿåº¦ä¿¡æ¯
            for key in observation.keys():
                if 'vel' in key or 'velocity' in key:
                    velocities.append(abs(observation[key]))
            
            if velocities:
                max_velocity = max(velocities)
                return max_velocity < velocity_threshold
                
        except Exception as e:
            logging.warning(f"æ£€æŸ¥æœºå™¨äººç¨³å®šæ€§æ—¶å‡ºé”™: {e}")
            
        return True  # é»˜è®¤è¿”å›ç¨³å®š
    
    def _is_operation_complete(self, observation):
        """æ£€æŸ¥æ“ä½œæ˜¯å¦å®Œæˆ"""
        # ç¤ºä¾‹ï¼šæ£€æŸ¥æ“ä½œä»»åŠ¡æ˜¯å¦å®Œæˆ
        try:
            # æ£€æŸ¥å¤¹çˆªä½ç½®æ¥åˆ¤æ–­æ“ä½œæ˜¯å¦å®Œæˆ
            gripper_positions = []
            for key in observation.keys():
                if 'gripper' in key and '.pos' in key:
                    gripper_positions.append(observation[key])
            
            if gripper_positions:
                # å¦‚æœå¤¹çˆªå®Œå…¨é—­åˆæˆ–å®Œå…¨æ‰“å¼€ï¼Œè®¤ä¸ºæ“ä½œå®Œæˆ
                avg_gripper_pos = sum(gripper_positions) / len(gripper_positions)
                return avg_gripper_pos < 10 or avg_gripper_pos > 30
                
        except Exception as e:
            logging.warning(f"æ£€æŸ¥æ“ä½œå®ŒæˆçŠ¶æ€æ—¶å‡ºé”™: {e}")
            
        return False  # é»˜è®¤è¿”å›æœªå®Œæˆ
    
    def get_current_state_info(self):
        """è·å–å½“å‰çŠ¶æ€ä¿¡æ¯"""
        return {
            "current_state": self.current_state.name,
            "step_count": self.step_count,
            "operation_count": self.operation_count,
            "max_operation_cycles": self.max_operation_cycles,
            "transitions": self.state_transition_log[-5:]  # æœ€è¿‘5æ¬¡çŠ¶æ€è½¬æ¢
        }


@dataclass
class DatasetRecordConfig:
    # Dataset identifier. By convention it should match '{hf_username}/{dataset_name}' (e.g. `lerobot/test`).
    repo_id: str
    # A short but accurate description of the task performed during the recording (e.g. "Pick the Lego block and drop it in the box on the right.")
    single_task: str
    # Root directory where the dataset will be stored (e.g. 'dataset/path').
    root: str | Path | None = None
    # Limit the frames per second.
    fps: int = 30
    # Number of seconds for data recording for each episode.
    episode_time_s: int | float = 60
    # Number of seconds for resetting the environment after each episode.
    reset_time_s: int | float = 10
    # Number of episodes to record.
    num_episodes: int = 50
    # Encode frames in the dataset into video
    video: bool = True
    # Upload dataset to Hugging Face hub.
    push_to_hub: bool = False
    # Upload on private repository on the Hugging Face hub.
    private: bool = False
    # Add tags to your dataset on the hub.
    tags: list[str] | None = None
    # Number of subprocesses handling the saving of frames as PNG. Set to 0 to use threads only;
    # set to â‰¥1 to use subprocesses, each using threads to write images. The best number of processes
    # and threads depends on your system. We recommend 4 threads per camera with 0 processes.
    # If fps is unstable, adjust the thread count. If still unstable, try using 1 or more subprocesses.
    num_image_writer_processes: int = 0
    # Number of threads writing the frames as png images on disk, per camera.
    # Too many threads might cause unstable teleoperation fps due to main thread being blocked.
    # Not enough threads might cause low camera fps.
    num_image_writer_threads_per_camera: int = 4
    # Number of episodes to record before batch encoding videos
    # Set to 1 for immediate encoding (default behavior), or higher for batched encoding
    video_encoding_batch_size: int = 1

    def __post_init__(self):
        if self.single_task is None:
            raise ValueError("You need to provide a task as argument in `single_task`.")


@dataclass
class RecordConfig:
    robot: RobotConfig
    dataset: DatasetRecordConfig
    # Whether to control the robot with a teleoperator
    teleop: TeleoperatorConfig | None = None
    # Whether to control the robot with a policy
    policy: PreTrainedConfig | None = None
    # Display all cameras on screen
    display_data: bool = False
    # Use vocal synthesis to read events.
    play_sounds: bool = True
    # Resume recording on an existing dataset.
    resume: bool = False

    def __post_init__(self):
        # HACK: We parse again the cli args here to get the pretrained path if there was one.
        policy_path = parser.get_path_arg("policy")
        if policy_path:
            cli_overrides = parser.get_cli_overrides("policy")
            self.policy = PreTrainedConfig.from_pretrained(policy_path, cli_overrides=cli_overrides)
            self.policy.pretrained_path = policy_path

        if self.teleop is None and self.policy is None:
            raise ValueError("Choose a policy, a teleoperator or both to control the robot")

    @classmethod
    def __get_path_fields__(cls) -> list[str]:
        """This enables the parser to load config from the policy using `--policy.path=local/dir`"""
        return ["policy"]


@safe_stop_image_writer
def record_loop(
    robot: Robot,
    events: dict,
    fps: int,
    dataset: LeRobotDataset | None = None,
    teleop: Teleoperator | list[Teleoperator] | None = None,
    policy: PreTrainedPolicy | None = None,
    control_time_s: int | None = None,
    single_task: str | None = None,
    display_data: bool = False,
    action_queue: deque | None = None,
    state_machine: StateMachine | None = None,  # æ·»åŠ çŠ¶æ€æœºå‚æ•°
):
    if dataset is not None and dataset.fps != fps:
        raise ValueError(f"The dataset fps should be equal to requested fps ({dataset.fps} != {fps}).")

    teleop_arm = teleop_keyboard = None
    if isinstance(teleop, list):
        teleop_keyboard = next((t for t in teleop if isinstance(t, KeyboardTeleop)), None)
        teleop_arm = next(
            (
                t
                for t in teleop
                if isinstance(
                    t,
                    (
                        so100_leader.SO100Leader,
                        so101_leader.SO101Leader,
                        koch_leader.KochLeader,
                    ),
                ),
            ),
            None,
        )

        if not (teleop_arm and teleop_keyboard and len(teleop) == 2 and robot.name == "lekiwi_client"):
            raise ValueError(
                "For multi-teleop, the list must contain exactly one KeyboardTeleop and one arm teleoperator. Currently only supported for LeKiwi robot."
            )

    # if policy is given it needs cleaning up
    if policy is not None:
        policy.reset()

    # åˆå§‹åŒ–åŠ¨ä½œé˜Ÿåˆ—
    if action_queue is None:
        action_queue = deque()
        
    # åˆå§‹åŒ–çŠ¶æ€æœºï¼ˆå¦‚æœæœªæä¾›ï¼‰
    if state_machine is None:
        state_machine = StateMachine(state_check_interval=300)

    timestamp = 0
    start_episode_t = time.perf_counter()
    while timestamp < control_time_s:
        start_loop_t = time.perf_counter()

        current_events = teleop.get_vr_events()
        events.update(current_events)

        # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ç»“æŸçŠ¶æ€ï¼Œå¦‚æœæ˜¯åˆ™æå‰é€€å‡º
        if state_machine.current_state == RobotState.END:
            logging.info("åˆ°è¾¾ç»“æŸçŠ¶æ€ï¼Œæå‰é€€å‡ºå½•åˆ¶å¾ªç¯")
            break

        if events["exit_early"]:
            events["exit_early"] = False
            log_say("Exit early")
            time.sleep(1)
            break

        try:
            observation = robot.get_observation()
        except TimeoutError as e:
            logging.warning(f"Camera timeout: {e}. Skipping this frame.")
            continue  # è·³è¿‡å½“å‰å¸§ï¼Œç»§ç»­å¾ªç¯

        # æ›´æ–°çŠ¶æ€æœº
        current_state = state_machine.update(observation, action_queue, robot, teleop)
        
        # æ ¹æ®å½“å‰çŠ¶æ€æ‰§è¡Œç›¸åº”çš„è¡Œä¸º
        state_info = state_machine.get_current_state_info()
        if dataset is not None:
            # å°†çŠ¶æ€ä¿¡æ¯æ·»åŠ åˆ°è§‚æµ‹æ•°æ®ä¸­
            observation["current_state"] = current_state.value
            observation["state_step_count"] = state_machine.step_count
            observation["operation_count"] = state_machine.operation_count

        if policy is not None or dataset is not None:
            observation_frame = build_dataset_frame(dataset.features, observation, prefix="observation")
        
        # å¦‚æœé˜Ÿåˆ—é‡Œæœ‰actionç›´æ¥æ‰§è¡Œ, ä¸é‡‡é›†action
        if action_queue:
            action = action_queue.popleft()
            if action == {}: # flag for the reset
                action = teleop.move_to_zero_position(robot)

        elif policy is not None:
            action_values = predict_action(
                observation_frame,
                policy,
                get_safe_torch_device(policy.config.device),
                policy.config.use_amp,
                task=single_task,
                robot_type=robot.robot_type,
            )
            action = {key: action_values[i].item() for i, key in enumerate(robot.action_features)}
        elif policy is None and isinstance(teleop, Teleoperator):
            action = teleop.get_action(observation, robot)
        elif policy is None and isinstance(teleop, list):
            # TODO(pepijn, steven): clean the record loop for use of multiple robots (possibly with pipeline)
            arm_action = teleop_arm.get_action()
            arm_action = {f"arm_{k}": v for k, v in arm_action.items()}

            keyboard_action = teleop_keyboard.get_action()
            base_action = robot._from_keyboard_to_base_action(keyboard_action)

            action = {**arm_action, **base_action} if len(base_action) > 0 else arm_action
        else:
            logging.info(
                "No policy or teleoperator provided, skipping action generation."
                "This is likely to happen when resetting the environment without a teleop device."
                "The robot won't be at its rest position at the start of the next episode."
            )
            continue

        # Action can eventually be clipped using `max_relative_target`,
        # so action actually sent is saved in the dataset.

        if events["reset_position"]:
            logging.info("Rest to the zero position of robot")
            log_say("Reset position")
            action = teleop.move_to_zero_position(robot)
            teleop.vr_event_handler.events['reset_position'] = False
            events["reset_position"] = False  # é‡ç½®äº‹ä»¶çŠ¶æ€
        elif events["back_position"]:
            logging.info("Back to the backet position of robot")
            log_say("Back backet position")
            if len(action_queue) < 10:  # å¦‚æœé˜Ÿåˆ—é‡Œæœ‰å¾ˆå¤šåŠ¨ä½œå°±ä¸åŠ å…¥å¤ä½åŠ¨ä½œ
                # æ”¾ç½®æ¾æ‰‹,å’Œå¤ä½ä¸€ä½“åŒ–
                queue_reset_actions(action_queue, robot, GLOBAL_BACK_GOAL, steps=30)
                queue_reset_actions(action_queue, robot, GLOBAL_OPEN_GOAL, steps=10, start_position=GLOBAL_BACK_GOAL)
                queue_reset_actions(action_queue, robot, np.zeros(12), steps=30, start_position=GLOBAL_OPEN_GOAL)
                action_queue.append({}) # reset to zero flag
            teleop.vr_event_handler.events['back_position'] = False
            events["back_position"] = False  # è¿”å›äº‹ä»¶çŠ¶æ€
            
        sent_action = robot.send_action(action)

        if dataset is not None:
            action_frame = build_dataset_frame(dataset.features, sent_action, prefix="action")
            frame = {**observation_frame, **action_frame, "task": single_task}
            dataset.add_frame(frame)

        if display_data:
            log_rerun_data(observation, action)
            # åœ¨å¯è§†åŒ–ä¸­æ˜¾ç¤ºå½“å‰çŠ¶æ€
            if "current_state" in observation:
                logging.debug(f"å½“å‰çŠ¶æ€: {RobotState(observation['current_state']).name}")

        dt_s = time.perf_counter() - start_loop_t
        busy_wait(1 / fps - dt_s)

        timestamp = time.perf_counter() - start_episode_t


@parser.wrap()
def record(cfg: RecordConfig) -> LeRobotDataset:
    init_logging()
    logging.info(pformat(asdict(cfg)))
    if cfg.display_data:
        init_rerun(session_name="recording")

    robot = make_robot_from_config(cfg.robot)
    teleop = make_teleoperator_from_config(cfg.teleop) if cfg.teleop is not None else None

    action_features = hw_to_dataset_features(robot.action_features, "action", cfg.dataset.video)
    obs_features = hw_to_dataset_features(robot.observation_features, "observation", cfg.dataset.video)
    dataset_features = {**action_features, **obs_features}

    if cfg.resume:
        dataset = LeRobotDataset(
            cfg.dataset.repo_id,
            root=cfg.dataset.root,
            batch_encoding_size=cfg.dataset.video_encoding_batch_size,
        )

        if hasattr(robot, "cameras") and len(robot.cameras) > 0:
            dataset.start_image_writer(
                num_processes=cfg.dataset.num_image_writer_processes,
                num_threads=cfg.dataset.num_image_writer_threads_per_camera * len(robot.cameras),
            )
        sanity_check_dataset_robot_compatibility(dataset, robot, cfg.dataset.fps, dataset_features)
    else:
        # Create empty dataset or load existing saved episodes
        sanity_check_dataset_name(cfg.dataset.repo_id, cfg.policy)
        dataset = LeRobotDataset.create(
            cfg.dataset.repo_id,
            cfg.dataset.fps,
            root=cfg.dataset.root,
            robot_type=robot.name,
            features=dataset_features,
            use_videos=cfg.dataset.video,
            image_writer_processes=cfg.dataset.num_image_writer_processes,
            image_writer_threads=cfg.dataset.num_image_writer_threads_per_camera * len(robot.cameras),
            batch_encoding_size=cfg.dataset.video_encoding_batch_size,
        )

    # Load pretrained policy
    policy = None if cfg.policy is None else make_policy(cfg.policy, ds_meta=dataset.meta)

    robot.connect()
    if teleop is not None:
        teleop.connect(robot=robot)
        teleop.send_feedback()

    # æ ¹æ®teleopç±»å‹é€‰æ‹©åˆé€‚çš„äº‹ä»¶ç›‘å¬å™¨
    if isinstance(teleop, XLerobotVRTeleop):
        # ä½¿ç”¨VRäº‹ä»¶ç›‘å¬å™¨
        listener, events = init_vr_listener(teleop)
        logging.info("ğŸ® ä½¿ç”¨VRå·¦æ‰‹æŸ„æ§åˆ¶å½•åˆ¶çŠ¶æ€")
    else:
        # ä½¿ç”¨ä¼ ç»Ÿé”®ç›˜ç›‘å¬å™¨
        listener, events = init_keyboard_listener()
        logging.info("âŒ¨ï¸ ä½¿ç”¨é”®ç›˜æ§åˆ¶å½•åˆ¶çŠ¶æ€")

    # åˆå§‹åŒ–çŠ¶æ€æœº
    state_machine = StateMachine(state_check_interval=300)
    logging.info("ğŸš€ çŠ¶æ€æœºå·²åˆå§‹åŒ–ï¼Œæ¯300æ­¥æ£€æŸ¥çŠ¶æ€è½¬æ¢")

    with VideoEncodingManager(dataset):
        recorded_episodes = 0
        while recorded_episodes < cfg.dataset.num_episodes and not events["stop_recording"]:
            log_say(f"Recording episode {dataset.num_episodes}", cfg.play_sounds)
            time.sleep(3)
            record_loop(
                robot=robot,
                events=events,
                fps=cfg.dataset.fps,
                teleop=teleop,
                policy=policy,
                dataset=dataset,
                control_time_s=cfg.dataset.episode_time_s,
                single_task=cfg.dataset.single_task,
                display_data=cfg.display_data,
                state_machine=state_machine,  # ä¼ é€’çŠ¶æ€æœº
            )

            # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ç»“æŸçŠ¶æ€
            if state_machine.current_state == RobotState.END:
                logging.info("ä»»åŠ¡å®Œæˆï¼Œæå‰ç»“æŸå½•åˆ¶")
                break

            # Execute a few seconds without recording to give time to manually reset the environment
            # Skip reset for the last episode to be recorded
            if not events["stop_recording"] and (
                (recorded_episodes < cfg.dataset.num_episodes - 1) or events["rerecord_episode"]
            ):
                log_say("Reset environment", cfg.play_sounds)
                record_loop(
                    robot=robot,
                    events=events,
                    fps=cfg.dataset.fps,
                    teleop=teleop,
                    control_time_s=cfg.dataset.reset_time_s,
                    single_task=cfg.dataset.single_task,
                    display_data=cfg.display_data,
                    dataset=None,
                    state_machine=state_machine,  # ä¼ é€’çŠ¶æ€æœº
                )

            if events["rerecord_episode"]:
                log_say("Delete Again record", cfg.play_sounds)
                events["rerecord_episode"] = False
                events["exit_early"] = False
                teleop.vr_event_handler.events['rerecord_episode'] = False

                dataset.clear_episode_buffer()
                time.sleep(10)
                continue

            log_say("Saving Episode", cfg.play_sounds, blocking=True)

            dataset.save_episode()
            recorded_episodes += 1

    log_say("Stop recording", cfg.play_sounds, blocking=True)

    robot.disconnect()
    if teleop is not None:
        teleop.disconnect()

    if not is_headless() and listener is not None:
        listener.stop()

    if cfg.dataset.push_to_hub:
        dataset.push_to_hub(tags=cfg.dataset.tags, private=cfg.dataset.private)

    log_say("Exiting", cfg.play_sounds)
    return dataset


def main():
    record()


if __name__ == "__main__":
    main()
